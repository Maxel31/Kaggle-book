{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 カテゴリ変数の変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/sample-data/train.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../input/sample-data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_saved = train_x.copy()\n",
    "test_x_saved = test_x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_x, test_x = train_x_saved.copy(), test_x_saved.copy()\n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['sex', 'product', 'medical_info_b2', 'medical_info_b3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータを結合してget_dummiesによるone-hot encodingを行う\n",
    "all_x = pd.concat([train_x, test_x])\n",
    "all_x = pd.get_dummies(all_x, columns=cat_cols)\n",
    "\n",
    "# 学習データとテストデータに再分割\n",
    "train_x = all_x.iloc[:train_x.shape[0], :].reset_index(drop=True)\n",
    "test_x = all_x.iloc[train_x.shape[0]:, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shion31/dev/kaggle-book/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OneHotEncoderでのencoding\n",
    "ohe = OneHotEncoder(sparse=False, categories='auto')\n",
    "ohe.fit(train_x[cat_cols])\n",
    "\n",
    "# ダミー変数の列名の作成\n",
    "columns = []\n",
    "for i, c in enumerate(cat_cols):\n",
    "    columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
    "\n",
    "# 生成されたダミー変数をデータフレームに変換\n",
    "dummy_vals_train = pd.DataFrame(ohe.transform(train_x[cat_cols]), columns=columns)\n",
    "dummy_vals_test = pd.DataFrame(ohe.transform(test_x[cat_cols]), columns=columns)\n",
    "\n",
    "# 残りの変数と結合\n",
    "train_x = pd.concat([train_x.drop(cat_cols, axis=1), dummy_vals_train], axis=1)\n",
    "test_x = pd.concat([test_x.drop(cat_cols, axis=1), dummy_vals_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# カテゴリ変数をループしてlabel encoding\n",
    "for c in cat_cols:\n",
    "    # 学習データに基づいて定義する\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[c])\n",
    "    train_x[c] = le.transform(train_x[c])\n",
    "    test_x[c] = le.transform(test_x[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# カテゴリ変数をループしてfeature hashing\n",
    "for c in cat_cols:\n",
    "    # FeatureHasherの使い方は、他のencoderとは少し異なる\n",
    "\n",
    "    fh = FeatureHasher(n_features=5, input_type='string')\n",
    "    # 変数を文字列に変換してからFeatureHasherを適用\n",
    "    hash_train = fh.transform(train_x[[c]].astype(str).values)\n",
    "    hash_test = fh.transform(test_x[[c]].astype(str).values)\n",
    "    # データフレームに変換\n",
    "    hash_train = pd.DataFrame(hash_train.todense(), columns=[f'{c}_{i}' for i in range(5)])\n",
    "    hash_test = pd.DataFrame(hash_test.todense(), columns=[f'{c}_{i}' for i in range(5)])\n",
    "    # 元のデータフレームと結合\n",
    "    train_x = pd.concat([train_x, hash_train], axis=1)\n",
    "    test_x = pd.concat([test_x, hash_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 frequency encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数をループしてfrequency encoding\n",
    "for c in cat_cols:\n",
    "    freq = train_x[c].value_counts()\n",
    "    # カテゴリの出現回数で置換\n",
    "    train_x[c] = train_x[c].map(freq)\n",
    "    test_x[c] = test_x[c].map(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.5 target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 変数をループしてtarget encoding\n",
    "for c in cat_cols:\n",
    "    # 学習データ全体で各カテゴリにおけるtargetの平均を計算\n",
    "    data_tmp = pd.DataFrame({c: train_x[c], 'target': train_y})\n",
    "    target_mean = data_tmp.groupby(c)['target'].mean()\n",
    "    # テストデータのカテゴリを置換\n",
    "    test_x[c] = test_x[c].map(target_mean)\n",
    "\n",
    "    # 学習データの変換後の値を格納する配列を準備\n",
    "    tmp = np.repeat(np.nan, train_x.shape[0])\n",
    "\n",
    "    # 学習データを分割\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=72)\n",
    "    for idx_1, idx_2 in kf.split(train_x):\n",
    "        # out-of-foldで各カテゴリにおける目的変数の平均を計算\n",
    "        target_mean = data_tmp.iloc[idx_1].groupby(c)['target'].mean()\n",
    "        # 変換後の値を一時配列に格納\n",
    "        tmp[idx_2] = train_x[c].iloc[idx_2].map(target_mean)\n",
    "\n",
    "    # 変換後のデータで元の変数を置換\n",
    "    train_x[c] = tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
