{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 モデルとは何か?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# データ等の準備\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "\n",
    "train = pd.read_csv('../input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../input/sample-data/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# コードの動作を確認するためのモデル\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y):\n",
    "        params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "        params.update(self.params)\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        self.model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:47:02] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"param1\", \"param2\", \"silent\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# モデルの学習と予測\n",
    "# -----------------------------------\n",
    "# モデルのハイパーパラメータを指定する\n",
    "params = {'param1': 10, 'param2': 100}\n",
    "\n",
    "# Modelクラスを定義しているものとする\n",
    "# Modelクラスは、fitで学習し、predictで予測値の確率を出力する\n",
    "\n",
    "# モデルを定義する\n",
    "model = Model(params)\n",
    "\n",
    "# 学習データに対してモデルを学習させる\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# テストデータに対して予測結果を出力する\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:48:45] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"param1\", \"param2\", \"silent\" } are not used.\n",
      "\n",
      "logloss: 0.3009\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# バリデーション\n",
    "# -----------------------------------\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 学習データ・バリデーションデータを分けるためのインデックスを作成する\n",
    "# 学習データを4つに分割し、うち1つをバリデーションデータとする\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "\n",
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "# モデルを定義する\n",
    "model = Model(params)\n",
    "\n",
    "# 学習データに対してモデルを学習させる\n",
    "# モデルによっては、バリデーションデータを同時に与えてスコアをモニタリングすることができる\n",
    "model.fit(tr_x, tr_y)\n",
    "\n",
    "# バリデーションデータに対して予測し、評価を行う\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:09] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"param1\", \"param2\", \"silent\" } are not used.\n",
      "\n",
      "[18:59:09] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"param1\", \"param2\", \"silent\" } are not used.\n",
      "\n",
      "[18:59:09] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"param1\", \"param2\", \"silent\" } are not used.\n",
      "\n",
      "[18:59:09] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"param1\", \"param2\", \"silent\" } are not used.\n",
      "\n",
      "logloss: 0.2967\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# クロスバリデーション\n",
    "# -----------------------------------\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 学習データを4つに分け、うち1つをバリデーションデータとする\n",
    "# どれをバリデーションデータとするかを変えて学習・評価を4回行う\n",
    "scores = []\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "    model = Model(params)\n",
    "    model.fit(tr_x, tr_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# クロスバリデーションの平均のスコアを出力する\n",
    "print(f'logloss: {np.mean(scores):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
